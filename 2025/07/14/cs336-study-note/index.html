

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="stylesheet" href="https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css" media="print" onload="this.media='all'">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/ucas.webp">
  <link rel="icon" href="/img/ucas.webp">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Munger Yang">
  <meta name="keywords" content="">
  
    <meta name="description" content="CS336: Language Modeling from Scratch      Stanford &#x2F; Spring 2025      学习笔记整理：杨桂淼     课程主页：https:&#x2F;&#x2F;stanford-cs336.github.io&#x2F;spring2025&#x2F;   GoalThis course is designed to provide students with a comp">
<meta property="og:type" content="article">
<meta property="og:title" content="cs336:Language Modeling from Scratch">
<meta property="og:url" content="http://example.com/2025/07/14/cs336-study-note/index.html">
<meta property="og:site_name" content="munger写字的地方">
<meta property="og:description" content="CS336: Language Modeling from Scratch      Stanford &#x2F; Spring 2025      学习笔记整理：杨桂淼     课程主页：https:&#x2F;&#x2F;stanford-cs336.github.io&#x2F;spring2025&#x2F;   GoalThis course is designed to provide students with a comp">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://stanford-cs336.github.io/spring2025/images/stanford-nlp-logo-new.jpg">
<meta property="article:published_time" content="2025-07-14T02:40:26.000Z">
<meta property="article:modified_time" content="2025-07-25T09:13:32.800Z">
<meta property="article:author" content="Munger Yang">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://stanford-cs336.github.io/spring2025/images/stanford-nlp-logo-new.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>cs336:Language Modeling from Scratch - munger写字的地方</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/shubiao.css">
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/bynotes/texiao/source/css/gundongtiao.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":75,"cursorChar":"_","loop":true,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Munger Yang&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about" target="_self">
                <i class="iconfont icon-addrcard"></i>
                <span>主页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-books"></i>
                <span>博客</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="/" target="_self">
                    <i class="iconfont icon-pen"></i>
                    <span>文章</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/archives/" target="_self">
                    <i class="iconfont icon-archive-fill"></i>
                    <span>总览</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/categories/" target="_self">
                    <i class="iconfont icon-category-fill"></i>
                    <span>分类</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/tags/" target="_self">
                    <i class="iconfont icon-tags-fill"></i>
                    <span>标签</span>
                  </a>
                
              </div>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/picture" target="_self">
                <i class="iconfont icon-image"></i>
                <span>照片墙</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/self/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>简历</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>友链</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg/paper.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="cs336:Language Modeling from Scratch"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-07-14 10:40" pubdate>
          2025年7月14日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.7k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          15 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">cs336:Language Modeling from Scratch</h1>
            
            
              <div class="markdown-body">
                
                <center>
  <h1>CS336: Language Modeling from Scratch</h1>
</center>

<center>
  <h1>Stanford / Spring 2025</h1>
</center>

<center>
  学习笔记整理：杨桂淼
</center>
<center>
  课程主页：https://stanford-cs336.github.io/spring2025/
</center>

<h2 id="Goal"><a href="#Goal" class="headerlink" title="Goal"></a>Goal</h2><p>This course is designed to provide students with a comprehensive understanding of language models by walking them through the entire process of developing their own. Drawing inspiration from operating systems courses that create an entire operating system from scratch, we will lead students through every aspect of language model creation, including data collection and cleaning for pre-training, transformer model construction, model training, and evaluation before deployment.</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/design-decisions.png" srcset="/img/loading.gif" lazyload alt="design-decisions"></p>
<h2 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h2><p>Tokenizers是将字符串和整数序列之间进行相互转换，四类主要的分词器：character_tokenizer、byte_tokenizer、word_tokenizer、bpe_tokenizer。</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/images/tokenized-example.png" srcset="/img/loading.gif" lazyload alt="Tokenization"></p>
<p>character_tokenizer：每个字符可以通过<code>ord</code>函数完成字符到ASCII码(Unicode)的相互转换。但是带来的问题就是构成的词表非常大，许多字符生僻少用导致词汇使用效率低。</p>
<p>byte_tokenizer：Unicode字符可以被表示为一个使用0-255整数表示的<strong>字节序列</strong>。但是由于一个字节只能被256个整数所表示，这就造成了经过Tokenization后的序列长度会变得非常长。</p>
<p>word_tokenizer：NLP领域内常用的方法是将字符串分割为单词，利用正则表达式构建分词器，将基于分词器得到的segments映射为整数，构建出每个segment的整数映射。但是存在的问题是单词的数量巨大，无法提供固定的词汇量；训练期间未使用过的新词会被标记为UNK，扰乱困惑度计算。</p>
<p>💡联想语言模型的输出：LLM的输出本质上就是在一个大的词表上预测单词的概率分布，如果词表非常大，那么计算了可想而知是非常恐怖的，而且也会影响token的预测。上面介绍的三种Tokenization都各有特点，但是也都存在致命的缺点。LLM基于上述编码的劣势，最终选择采用BPE算法作为模型的Tokenization方法。</p>
<h3 id="Byte-Pair-Encoding"><a href="#Byte-Pair-Encoding" class="headerlink" title="Byte Pair Encoding"></a>Byte Pair Encoding</h3><p>BPE算法是在1994年发表的“A New Algorithm for Data Compression”提出的一种新型<strong>数据压缩</strong>算法。核心思想就是将序列中常见的一对<strong>相邻的数据单元</strong>替换为数据中没有出现过的新单元，反复迭代直至满足终止条件。</p>
<p>bpe_tokenizer：基本思路是常见的字符序列被单个token表示，罕见的序列被多个tokens表示。</p>
<p>BPE的基本计算路程如下所示：</p>
<img src="/img/fig/bpe.jpg" srcset="/img/loading.gif" lazyload/>





<h2 id="Pytorch-and-Resource-accounting"><a href="#Pytorch-and-Resource-accounting" class="headerlink" title="Pytorch and Resource accounting"></a>Pytorch and Resource accounting</h2><h3 id="tensors-memory"><a href="#tensors-memory" class="headerlink" title="tensors_memory"></a>tensors_memory</h3><p>Higher precision: more accurate&#x2F;stable, more memory, more compute</p>
<p>Lower precision: less accurate&#x2F;stable, less memory, less compute</p>
<ul>
<li>float32：单精度浮点数是tensor的默认数据类型，4个字节表示一个浮点数。1位符号位， 8位指数位， 23位小数位。神经网络训练时，创建tensor默认的数据类型。</li>
</ul>
<p>当符号位为0，指数位为11111110，尾数位为全1时，float32的最大值为 $2^{127} \times (1+\frac{2^{23}-1}{2^{23}}&#x3D;3.40e38$；</p>
<p>当符号位为1，指数位为11111110，尾数位为全1时，float32的最小值为$-2^{127} \times (1+\frac{2^{23}-1}{2^{23}}&#x3D;-3.40e38$。</p>
<ul>
<li>float16：半精度浮点数，两个字节表示一个浮点数。1位符号位， 5位指数位， 10位小数位。相比于float32所占内存更小，但是会出现<strong>溢出问题</strong>。</li>
</ul>
<p>当符号位为0，指数位为11110，尾数位为全1时，float16的最大值为 $2^{15} \times (1+\frac{1023}{1024})&#x3D;65504$；</p>
<p>当符号位为1，指数位为11110，尾数位为全1时，float16的最小值为$-2^{15} \times (1+\frac{1023}{1024}) &#x3D; -65504$。</p>
<ul>
<li>bfloat16：与float16所占内存一致，但是具有float32的存储范围。1位符号位， 8位指数位， 7位小数位。</li>
</ul>
<p>计算<code>矩阵乘法</code>与<code>前向传播</code>时推荐使用bfloat16数据类型，计算<code>Attention注意力</code>时推荐使用float32数据类型。</p>
<p>指数的偏置：</p>
<ul>
<li><code>float32</code> 的 Bias 为 127</li>
<li><code>float16</code> 的 Bias 为 15</li>
<li><code>bfloat16</code> 的 Bias 为 127</li>
</ul>
<p><img src="https://githubraw.cdn.bcebos.com/PaddlePaddle/docs/develop/docs/guides/performance_improving/images/float.png?raw=true" srcset="/img/loading.gif" lazyload alt="FLOPS"></p>
<p>计算实例如下，以float16为例：</p>
<img src="/img/fig/float16.jpg" srcset="/img/loading.gif" lazyload/>

<h3 id="tensors-on-gpus"><a href="#tensors-on-gpus" class="headerlink" title="tensors_on_gpus"></a>tensors_on_gpus</h3><p>为了利用好GPUs的并行优势，我们需要将数据从CPU中的RAM移动到GPU中的DRAM中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> torch.cuda.is_available():<br>  <span class="hljs-keyword">return</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gpus):<br>  properties = torch.cuda.get_device_properties(i)  <span class="hljs-comment"># @inspect properties</span><br> <br>y = x.to(<span class="hljs-string">&quot;cuda:0&quot;</span>)<br><span class="hljs-keyword">assert</span> x.device == torch.device(<span class="hljs-string">&quot;cuda&quot;</span>,<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure>

<p>PyTorch中的tensors就是存储在内存中的指针，存储形式如下图所示：</p>
<p><img src="https://stanford-cs336.github.io/spring2025-lectures/var/files/image-97aa05a6701b46521cb8a7c1e096c7e7-https_martinlwx_github_io_img_2D_tensor_strides_png" srcset="/img/loading.gif" lazyload alt="tensor-pointer"></p>
<p>strides[1]表示列指针，strides[0]表示行指针；上图中二维格式为我们习惯上画出的存储格式，但是在内存条中存储的格式本质上是下图中的线性格式。如果要定位一个元素的位置(查找一个元素)，需要利用连个指针进行辅助：$pos&#x3D;1 * strides[1] + 4 * strides[0]$。</p>
<p>以元素10为例(2行3列)，$pos_{10}&#x3D;1 * 3 + 4 * 2 &#x3D; 11$，那么内存中横向第11个位置(从1计数)对应的元素即是10。</p>
<h3 id="tensor-operations"><a href="#tensor-operations" class="headerlink" title="tensor_operations"></a>tensor_operations</h3><p>Pytorch对于tensor的操作中，<code>view</code>是free，无须占用内存；但是copy操作(<code>contiguous and reshape</code>)是需要内存开销的。</p>
<p>⚠️<strong>einops</strong>是之前没有接触过的操作，主要作用是高效操作张量的维度，需要留心学习关注下。推荐一篇博文：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/342675997">https://zhuanlan.zhihu.com/p/342675997</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 矩阵乘法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensor_matmul</span>():<br>  x = torch.ones(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>)<br>  w = torch.ones(<span class="hljs-number">32</span>, <span class="hljs-number">2</span>)<br>  <br>y = x @ w<br><span class="hljs-keyword">assert</span> y.size() == torch.Size([<span class="hljs-number">16</span>, <span class="hljs-number">2</span>])<br><br><span class="hljs-comment"># 定义两个张量:</span><br>x: Float[torch.Tensor, <span class="hljs-string">&quot;batch seq1 hidden&quot;</span>] = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)  <span class="hljs-comment"># @inspect x</span><br>y: Float[torch.Tensor, <span class="hljs-string">&quot;batch seq2 hidden&quot;</span>] = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)  <span class="hljs-comment"># @inspect y</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tensor_einops</span>():<br>  <span class="hljs-comment">#einops主要是rearrange, reduce, repeat这3个方法</span><br>  z = x @ y.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># batch, sequence, sequence  @inspect z --&gt; Old way</span><br>  z = einsum(x, y, <span class="hljs-string">&quot;batch seq1 hidden, batch seq2 hidden -&gt; batch seq1 seq2&quot;</span>)  <span class="hljs-comment"># @inspect z --&gt; New (einops) way</span><br>  z = einsum(x, y, <span class="hljs-string">&quot;... seq1 hidden, ... seq2 hidden -&gt; ... seq1 seq2&quot;</span>)  <span class="hljs-comment"># @inspect z</span><br>  <span class="hljs-comment"># reduce</span><br>  x: Float[torch.Tensor, <span class="hljs-string">&quot;batch seq hidden&quot;</span>] = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)  <span class="hljs-comment"># @inspect x</span><br>  y = x.mean(dim=-<span class="hljs-number">1</span>)  <span class="hljs-comment"># @inspect y --&gt; Old way</span><br>  y = reduce(x,<span class="hljs-string">&quot;...hidden -&gt; ...&quot;</span>,<span class="hljs-string">&quot;sum&quot;</span>) --&gt; New (einops) way<br>  <span class="hljs-comment"># rearrange</span><br>  x: Float[torch.Tensor, <span class="hljs-string">&quot;batch seq total_hidden&quot;</span>] = torch.ones(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>)  <span class="hljs-comment"># @inspect x</span><br>  w: Float[torch.Tensor, <span class="hljs-string">&quot;hidden1 hidden2&quot;</span>] = torch.ones(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>)<br>  <br>  x = rearrange(x, <span class="hljs-string">&quot;... (heads hidden1) -&gt; ... heads hidden1&quot;</span>, heads=<span class="hljs-number">2</span>)  <span class="hljs-comment"># @inspect x</span><br>  x = einsum(x, w, <span class="hljs-string">&quot;... hidden1, hidden1 hidden2 -&gt; ... hidden2&quot;</span>)  <span class="hljs-comment"># @inspect x</span><br></code></pre></td></tr></table></figure>

<h3 id="Computational-cost"><a href="#Computational-cost" class="headerlink" title="Computational cost"></a>Computational cost</h3><p>LLM里的计算基本上都是浮点运算(FLOP)，类似于加法运算和乘法运算。</p>
<p>容易混淆的概念：</p>
<ul>
<li>FLOPs: 浮点运算次数</li>
<li>FLOP&#x2F;s：每秒钟浮点计算次数，衡量硬件指标</li>
</ul>
<p>对 m x n 矩阵进行元素运算需要 O(mn) FLOPs；两个 m x n 矩阵的加法需要 mn 次 FLOPs。一般来说，没有任何运算比矩阵乘法更耗时。</p>
<p>我们用 B 表示数据点的个数，(D K)是参数大小，2 (# tokens) (# parameters)代表前想传播的FLOPs、4 (# data points) (# parameters) 反向传播FLOPs、6 (# data points) (# parameters)代表一次训练的FLOPs。</p>
<p>一个重要指标：Model FLOPs utilization - 模型FLOPs利用率，计算公式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">mfu = actual_flop_per_sec / promised_flop_per_sec  <span class="hljs-comment"># @inspect mfu</span><br></code></pre></td></tr></table></figure>

<p>FLOP&#x2F;s取决于硬件(H100 &gt;&gt; A100) 和数据类型(bfloat16 &gt;&gt; float32)。</p>
<h3 id="Parameter-initialization"><a href="#Parameter-initialization" class="headerlink" title="Parameter initialization"></a>Parameter initialization</h3><p>初始化语法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">x = nn.Parameter(torch.randn(input_dim))<br>w = nn.Parameter(nn.init.trunc_normal_(torch.empty(input_dim, output_dim), std=<span class="hljs-number">1</span> / np.sqrt(input_dim), a=-<span class="hljs-number">3</span>, b=<span class="hljs-number">3</span>))<br></code></pre></td></tr></table></figure>

<p>维度缩放的原因：为了防止前向传播过程中发生梯度爆炸，导致训练不稳定；将输入进行1&#x2F;sqrt(input_dim) 缩放，这样每一步都会得到基于正太分布的输出，保证了数据的稳定性。这个道理在注意力机制的计算中同样适用。</p>
<p>⚠️数据加载的注意事项：Don’t want to load the entire data into memory at once！大语言模型的输入是整数序列，可以使用numpy数组加载这些数据，使用memap延迟加载部分数据到内存中。</p>
<p>optimizer的组成：</p>
<ul>
<li>momentum &#x3D; SGD + exponential averaging of grad</li>
<li>AdaGrad &#x3D; SGD + averaging by grad$^2$</li>
<li>RMSProp &#x3D; AdaGrad + exponentially averaging of grad$^2$</li>
<li>Adam &#x3D; RMSProp + momentum</li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="category-chain-item">人工智能与深度学习</a>
  
  

      </span>
    
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9B%B8%E5%85%B3/" class="category-chain-item">大模型相关</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/LLM/" class="print-no-link">#LLM</a>
      
        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="print-no-link">#深度学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>cs336:Language Modeling from Scratch</div>
      <div>http://example.com/2025/07/14/cs336-study-note/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Munger Yang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年7月14日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/07/29/Prompt-Compression/" title="Prompt Compression">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Prompt Compression</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/07/01/2025%E5%B9%B46%E6%9C%88%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B/" title="2025年6月总结与展望">
                        <span class="hidden-mobile">2025年6月总结与展望</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="waline"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#waline', function() {
      Fluid.utils.createCssLink('https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/waline.css')
      Fluid.utils.createScript('https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/waline.js', function() {
        var options = Object.assign(
          {"serverURL":"https://comment.mungeryang.top/","path":"window.location.pathname","meta":["nick","mail","link"],"requiredMeta":["nick"],"lang":"zh-CN","emoji":["https://cdn.jsdelivr.net/gh/walinejs/emojis/weibo"],"dark":"html[data-user-color-scheme=\"dark\"]","wordLimit":0,"pageSize":10},
          {
            el: '#waline',
            path: window.location.pathname
          }
        )
        Waline.init(options);
        Fluid.utils.waitElementVisible('#waline .vcontent', () => {
          var imgSelector = '#waline .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> <a target="_blank" rel="noopener" href="https://www.aliyun.com/">本网站由<img src="/img/aliyun.png" srcset="/img/loading.gif" lazyload width="65px" />提供CDN加速/云存储服务</a>
    </div>
  
  
    <div class="statistics">
  
  

  
    
    
    

  
</div>

  
  
    <!-- 备案信息 ICP for China -->
    <div class="beian">
  <span>
    <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
      京ICP备2024090304号
    </a>
  </span>
  
    
      <span>
        <a
          href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=12345678"
          rel="nofollow noopener"
          class="beian-police"
          target="_blank"
        >
          
            <span style="visibility: hidden; width: 0">|</span>
            <img src="/img/police_beian.png" srcset="/img/loading.gif" lazyload alt="police-icon"/>
          
          <span>京公网安备2024090304号</span>
        </a>
      </span>
    
  
</div>

  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="//cdn.jsdelivr.net/gh/bynotes/texiao/source/js/love.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
